{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for multimodal learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0 Import packages and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import ast\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>audio_url</th>\n",
       "      <th>search_method</th>\n",
       "      <th>emotion</th>\n",
       "      <th>lyrics_embedding</th>\n",
       "      <th>audio_embedding</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6481</td>\n",
       "      <td>Alexz Johnson</td>\n",
       "      <td>White Lines</td>\n",
       "      <td>0.678952</td>\n",
       "      <td>-2.333604</td>\n",
       "      <td>I tried to tell you\\nI've got to get away\\nI t...</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/eae97329ac7135a5...</td>\n",
       "      <td>artist_and_song</td>\n",
       "      <td>Relaxed</td>\n",
       "      <td>[0.5272476077079773, 1.168580174446106, 0.1721...</td>\n",
       "      <td>[0.7431232416583579, 0.20046921661336187, 0.23...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9075</td>\n",
       "      <td>Turntablerocker</td>\n",
       "      <td>No Melody</td>\n",
       "      <td>0.373325</td>\n",
       "      <td>-0.923151</td>\n",
       "      <td>We've got the song\\nBut they got no melody\\nNo...</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/4f397176ee912edf...</td>\n",
       "      <td>artist_and_song</td>\n",
       "      <td>Relaxed</td>\n",
       "      <td>[-0.5302870273590088, -1.6064175367355347, 1.8...</td>\n",
       "      <td>[2.089026585978773, 1.0356926605543044, 0.7353...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9082</td>\n",
       "      <td>Lamb</td>\n",
       "      <td>Zero</td>\n",
       "      <td>-0.367547</td>\n",
       "      <td>-0.939283</td>\n",
       "      <td>LAMB: ZERO\\n\\nThere's no one here today\\n'Caus...</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/f65a72ecfbf7c304...</td>\n",
       "      <td>artist_and_song</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[0.054062437266111374, 0.38927221298217773, -0...</td>\n",
       "      <td>[0.8801736065962609, 1.9399530531306048, 2.596...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10587</td>\n",
       "      <td>Einstuerzende Neubauten</td>\n",
       "      <td>Youme &amp; Meyou</td>\n",
       "      <td>0.526139</td>\n",
       "      <td>-1.628377</td>\n",
       "      <td>They build a ship each wintertime\\nFor launch ...</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/a2acca0ac29d3a0a...</td>\n",
       "      <td>artist_and_song</td>\n",
       "      <td>Relaxed</td>\n",
       "      <td>[-1.2014904022216797, -0.5136592388153076, -0....</td>\n",
       "      <td>[0.5157966639886593, 1.5658099646756507, 1.259...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9177</td>\n",
       "      <td>Mouse On Mars</td>\n",
       "      <td>Wipe That Sound</td>\n",
       "      <td>0.815393</td>\n",
       "      <td>0.662457</td>\n",
       "      <td>Kick the can\\nI kick, kick kick the can\\nI kic...</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/a803171c426e144d...</td>\n",
       "      <td>artist_and_song</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[-0.42865195870399475, 0.8299823999404907, 1.1...</td>\n",
       "      <td>[2.3368670630266033, 1.3798174751404781, 0.647...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              artist_name       track_name   valence   arousal  \\\n",
       "0        6481            Alexz Johnson      White Lines  0.678952 -2.333604   \n",
       "1        9075          Turntablerocker        No Melody  0.373325 -0.923151   \n",
       "2        9082                     Lamb             Zero -0.367547 -0.939283   \n",
       "3       10587  Einstuerzende Neubauten    Youme & Meyou  0.526139 -1.628377   \n",
       "4        9177            Mouse On Mars  Wipe That Sound  0.815393  0.662457   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  I tried to tell you\\nI've got to get away\\nI t...   \n",
       "1  We've got the song\\nBut they got no melody\\nNo...   \n",
       "2  LAMB: ZERO\\n\\nThere's no one here today\\n'Caus...   \n",
       "3  They build a ship each wintertime\\nFor launch ...   \n",
       "4  Kick the can\\nI kick, kick kick the can\\nI kic...   \n",
       "\n",
       "                                           audio_url    search_method  \\\n",
       "0  https://p.scdn.co/mp3-preview/eae97329ac7135a5...  artist_and_song   \n",
       "1  https://p.scdn.co/mp3-preview/4f397176ee912edf...  artist_and_song   \n",
       "2  https://p.scdn.co/mp3-preview/f65a72ecfbf7c304...  artist_and_song   \n",
       "3  https://p.scdn.co/mp3-preview/a2acca0ac29d3a0a...  artist_and_song   \n",
       "4  https://p.scdn.co/mp3-preview/a803171c426e144d...  artist_and_song   \n",
       "\n",
       "   emotion                                   lyrics_embedding  \\\n",
       "0  Relaxed  [0.5272476077079773, 1.168580174446106, 0.1721...   \n",
       "1  Relaxed  [-0.5302870273590088, -1.6064175367355347, 1.8...   \n",
       "2      Sad  [0.054062437266111374, 0.38927221298217773, -0...   \n",
       "3  Relaxed  [-1.2014904022216797, -0.5136592388153076, -0....   \n",
       "4    Happy  [-0.42865195870399475, 0.8299823999404907, 1.1...   \n",
       "\n",
       "                                     audio_embedding  label  \n",
       "0  [0.7431232416583579, 0.20046921661336187, 0.23...      2  \n",
       "1  [2.089026585978773, 1.0356926605543044, 0.7353...      2  \n",
       "2  [0.8801736065962609, 1.9399530531306048, 2.596...      3  \n",
       "3  [0.5157966639886593, 1.5658099646756507, 1.259...      2  \n",
       "4  [2.3368670630266033, 1.3798174751404781, 0.647...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('database/LaA_train.csv')\n",
    "df_test = pd.read_csv('database/LaA_test.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_audio_train = df_train['audio_embedding'].apply(ast.literal_eval).apply(np.array)\n",
    "x_audio_train = np.stack(embeddings_audio_train.values)\n",
    "embeddings_audio_test = df_test['audio_embedding'].apply(ast.literal_eval).apply(np.array)\n",
    "x_audio_test = np.stack(embeddings_audio_test.values)\n",
    "\n",
    "embeddings_lyrics_train = df_train['lyrics_embedding'].apply(ast.literal_eval).apply(np.array)\n",
    "x_lyrics_train = np.stack(embeddings_lyrics_train.values)\n",
    "embeddings_lyrics_test = df_test['lyrics_embedding'].apply(ast.literal_eval).apply(np.array)\n",
    "x_lyrics_test = np.stack(embeddings_lyrics_test.values)\n",
    "\n",
    "y_train = df_train['label']\n",
    "y_test = df_test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1 Train or load the models and get predictions\n",
    "Run the first cell to train the models, run the second one to load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pretrained_svms = True\n",
    "if use_pretrained_svms: \n",
    "    name_svm_audio = 'models/SVM_audio.joblib'\n",
    "    name_svm_lyrics = 'models/SVM_lyrics.joblib'\n",
    "    svm_classifier_audio = load(name_svm_audio)\n",
    "    svm_classifier_lyrics = load(name_svm_lyrics)\n",
    "else:\n",
    "    svm_classifier_lyrics = SVC(kernel='rbf', C=1, gamma='auto', probability=True)\n",
    "    svm_classifier_lyrics.fit(x_lyrics_train, y_train)\n",
    "    print(\"Lyrics SVM trained\")\n",
    "\n",
    "    svm_classifier_audio = SVC(kernel='rbf', C=1, gamma='auto', probability=True)\n",
    "    svm_classifier_audio.fit(x_audio_train, y_train)\n",
    "    print(\"Audio SVM trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the probabilities\n",
    "\n",
    "y_pred_test_prob_lyrics = svm_classifier_lyrics.predict_proba(x_lyrics_test)\n",
    "y_pred_test_prob_audio = svm_classifier_audio.predict_proba(x_audio_test)\n",
    "y_pred_train_prob_lyrics = svm_classifier_lyrics.predict_proba(x_lyrics_train)\n",
    "y_pred_train_prob_audio = svm_classifier_audio.predict_proba(x_audio_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics accuracy: 0.43\n",
      "Audio accuracy: 0.42\n"
     ]
    }
   ],
   "source": [
    "#get labels\n",
    "y_pred_lyrics = np.argmax(y_pred_test_prob_lyrics, axis=1)\n",
    "y_pred_audio = np.argmax(y_pred_test_prob_audio, axis=1)\n",
    "\n",
    "acc_lyrics, acc_audio = accuracy_score(y_test, y_pred_lyrics), accuracy_score(y_test, y_pred_audio)\n",
    "print(f\"Lyrics accuracy: {acc_lyrics:.2f}\")\n",
    "print(f\"Audio accuracy: {acc_audio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Models taking only the probabilities into account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 (Un)weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy first model: 0.45\n",
      "Accuracy modified first model: 0.45\n"
     ]
    }
   ],
   "source": [
    "# First model adds confidence scores of the two models and then takes the argmax\n",
    "y_pred_max_combined = np.argmax(y_pred_test_prob_lyrics + y_pred_test_prob_audio, axis=1)\n",
    "acc_max_combined = accuracy_score(y_test, y_pred_max_combined)\n",
    "print(f\"Accuracy first model: {acc_max_combined:.2f}\")\n",
    "\n",
    "# Variation: Use the weighted average. Weights are the accuracies of the individual models.\n",
    "y_pred_weighted_combined = np.argmax(acc_lyrics * y_pred_test_prob_lyrics + acc_audio * y_pred_test_prob_audio, axis=1)\n",
    "acc_weighted_combined = accuracy_score(y_test, y_pred_weighted_combined)\n",
    "print(f\"Accuracy modified first model: {acc_weighted_combined:.2f}\")\n",
    "\n",
    "# The scores for the evenly weighted models and the combined model are very similar. This is likely due to the fact that the accuracies of the two models are very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Confidence-based selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1.2.1 Proper confidence values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "# Second model takes the choice of the model that's more certain of its decision (i.e. the maximum probability)\n",
    "\n",
    "y_pred_max = np.argmax(np.maximum(y_pred_test_prob_lyrics, y_pred_test_prob_audio), axis=1)\n",
    "acc_max = accuracy_score(y_test, y_pred_max)\n",
    "print(f\"Accuracy: {acc_max:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Adjusted confidence values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we don't just take the choice of the model that's more confident, but we weight the confidence values with the resepctive model's performance in the given emotion class.\n",
    "\n",
    " **Example** : If model 1 chooses happy, has a mid confidence value while model 2 chooses sad with a higher confidence value, we still use model 1's choice in the case that model 1 is significantly better in classifying happy songs than model 2 is in classifying sad songs.\n",
    "\n",
    "**First step:** Calculate the accuracies of the models in the given classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = np.unique(y_train)\n",
    "\n",
    "accuracies_train_audio = {}\n",
    "accuracies_train_lyrics = {}\n",
    "\n",
    "# Convert y_train to a numpy array\n",
    "y_train_np = y_train.to_numpy()\n",
    "\n",
    "for label in unique_labels:\n",
    "    idx = np.where(y_train_np == label)\n",
    "\n",
    "    y_train_label = y_train_np[idx]\n",
    "    y_pred_train_prob_audio_label = np.argmax(y_pred_train_prob_audio[idx], axis=1)\n",
    "    y_pred_train_prob_lyrics_label = np.argmax(y_pred_train_prob_lyrics[idx], axis=1)\n",
    "\n",
    "    accuracies_train_audio[label] = accuracy_score(y_train_label, y_pred_train_prob_audio_label)\n",
    "    accuracies_train_lyrics[label] = accuracy_score(y_train_label, y_pred_train_prob_lyrics_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second step:** Weight the confidence values with the accuracies of the given model in the given emotion class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy of the combined model: 0.44\n"
     ]
    }
   ],
   "source": [
    "# Modification: Weight the confidence values with the accuracy of the model in the given class\n",
    "\n",
    "def calculate_combined_accuracy(y_test, y_pred_test_prob_audio, y_pred_test_prob_lyrics, accuracies_train_audio, accuracies_train_lyrics):\n",
    "    combined_predictions = []\n",
    "    \n",
    "    for audio_confidences, lyrics_confidences in zip(y_pred_test_prob_audio, y_pred_test_prob_lyrics):\n",
    "\n",
    "        adjusted_confidences_audio = {label: audio_confidences[label] * accuracies_train_audio[label] for label in range(len(audio_confidences))}\n",
    "        adjusted_confidences_lyrics = {label: lyrics_confidences[label] * accuracies_train_lyrics[label] for label in range(len(lyrics_confidences))}\n",
    "\n",
    "        combined_confidences = {label: max(adjusted_confidences_audio[label], adjusted_confidences_lyrics[label]) for label in adjusted_confidences_audio}        \n",
    "\n",
    "        final_prediction = max(combined_confidences, key=combined_confidences.get)\n",
    "        combined_predictions.append(final_prediction)\n",
    "    \n",
    "    total_accuracy = accuracy_score(y_test, combined_predictions)\n",
    "    return total_accuracy\n",
    "\n",
    "y_test_np = np.array(y_test)\n",
    "\n",
    "total_accuracy = calculate_combined_accuracy(y_test_np, y_pred_test_prob_audio, y_pred_test_prob_lyrics, accuracies_train_audio, accuracies_train_lyrics)\n",
    "\n",
    "print(f\"Total accuracy of the combined model: {total_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Weighting the confidence values doesn't give us a better prediction!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Second kind of models take probabilities as new input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add (If we want to add it in the presentation): How does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_meta_train = np.hstack((y_pred_train_prob_lyrics, y_pred_train_prob_audio))\n",
    "x_meta_test = np.hstack((y_pred_test_prob_lyrics, y_pred_test_prob_audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "meta_classifier_forest = RandomForestClassifier()\n",
    "meta_classifier_forest.fit(x_meta_train, y_train)\n",
    "y_pred_forest = meta_classifier_forest.predict(x_meta_test)\n",
    "acc_forest = accuracy_score(y_test, y_pred_forest)\n",
    "print(f\"Accuracy: {acc_forest:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Logistic regression with the confidence values\n",
    "\n",
    "Yet to be explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Using the same meta features as before\n",
    "meta_classifier_lr = LogisticRegression(max_iter=1000)\n",
    "meta_classifier_lr.fit(x_meta_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = meta_classifier_lr.predict(x_meta_test)\n",
    "acc_meta_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Accuracy: {acc_meta_lr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.7346339821815491\n",
      "Epoch 2/20, Loss: 0.6938502788543701\n",
      "Epoch 3/20, Loss: 0.49238133430480957\n",
      "Epoch 4/20, Loss: 0.7426857948303223\n",
      "Epoch 5/20, Loss: 0.589238703250885\n",
      "Epoch 6/20, Loss: 0.6927602291107178\n",
      "Epoch 7/20, Loss: 0.5901066660881042\n",
      "Epoch 8/20, Loss: 0.682794988155365\n",
      "Epoch 9/20, Loss: 0.6886836886405945\n",
      "Epoch 10/20, Loss: 0.7383273243904114\n",
      "Epoch 11/20, Loss: 0.47385212779045105\n",
      "Epoch 12/20, Loss: 0.5663787126541138\n",
      "Epoch 13/20, Loss: 0.43598952889442444\n",
      "Epoch 14/20, Loss: 0.43212762475013733\n",
      "Epoch 15/20, Loss: 0.4314401149749756\n",
      "Epoch 16/20, Loss: 0.49361732602119446\n",
      "Epoch 17/20, Loss: 0.6350902915000916\n",
      "Epoch 18/20, Loss: 0.6237216591835022\n",
      "Epoch 19/20, Loss: 0.6353707313537598\n",
      "Epoch 20/20, Loss: 0.6628891825675964\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "x_meta_train_tensor = torch.tensor(x_meta_train, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "x_meta_test_tensor = torch.tensor(x_meta_test, dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(x_meta_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataset = TensorDataset(x_meta_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "class MetaClassifierNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MetaClassifierNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)  # First hidden layer\n",
    "        self.fc2 = nn.Linear(128, 64)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(64, num_classes)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = MetaClassifierNN(input_size=8, num_classes=4)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Clear gradients for this training step\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Apply gradients\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 44.19%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad(): \n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy_NN = correct / total\n",
    "print(f'Accuracy on the test set: {accuracy_NN * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10870, 498)\n",
      "(10870, 768)\n"
     ]
    }
   ],
   "source": [
    "print(x_audio_train.shape)\n",
    "print(x_lyrics_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training an SVM on the combined feature space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to train the SVM on the combined featurespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two models\n",
    "x_train_combined = np.concatenate((x_audio_train, x_lyrics_train), axis = 1)\n",
    "x_test_combined = np.concatenate((x_audio_test, x_lyrics_test), axis = 1)\n",
    "\n",
    "x_train_combined.shape\n",
    "\n",
    "svm_classifier_combined = SVC(kernel='rbf', C=1, gamma='auto', probability=True)\n",
    "svm_classifier_combined.fit(x_train_combined, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "y_pred_combined = svm_classifier_combined.predict(x_test_combined)\n",
    "acc_combined = accuracy_score(y_test, y_pred_combined)\n",
    "print(f\"Accuracy: {acc_combined:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas for data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other things to mention in the presentation\n",
    "\n",
    "- We checked that the dataset is balanced\n",
    "- We checked that the models are not horribly over fitting (hopefully)\n",
    "- Explanation of audio features and how we acquired the data\n",
    "- Explanation of lyrical features and how we acquired it \n",
    "- Explanation of the arousal/valence scale\n",
    "- Short explanation SVM, mention scaling\n",
    "- Analysis of the two independent models\n",
    "- Introduction to ensemble learning, present different techniques\n",
    "- Discussion, what went wrong, what could be done better (both for the simple models and the bimodal model)\n",
    "- Perhaps comparison with Deezer paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
