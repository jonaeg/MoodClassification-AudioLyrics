{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import ast\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>audio_url</th>\n",
       "      <th>search_method</th>\n",
       "      <th>emotion</th>\n",
       "      <th>lyrics_embedding</th>\n",
       "      <th>audio_embedding</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6481</td>\n",
       "      <td>Alexz Johnson</td>\n",
       "      <td>White Lines</td>\n",
       "      <td>0.678952</td>\n",
       "      <td>-2.333604</td>\n",
       "      <td>I tried to tell you\\nI've got to get away\\nI t...</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/eae97329ac7135a5...</td>\n",
       "      <td>artist_and_song</td>\n",
       "      <td>Relaxed</td>\n",
       "      <td>[0.5272476077079773, 1.168580174446106, 0.1721...</td>\n",
       "      <td>[0.7431232416583579, 0.20046921661336187, 0.23...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9075</td>\n",
       "      <td>Turntablerocker</td>\n",
       "      <td>No Melody</td>\n",
       "      <td>0.373325</td>\n",
       "      <td>-0.923151</td>\n",
       "      <td>We've got the song\\nBut they got no melody\\nNo...</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/4f397176ee912edf...</td>\n",
       "      <td>artist_and_song</td>\n",
       "      <td>Relaxed</td>\n",
       "      <td>[-0.5302870273590088, -1.6064175367355347, 1.8...</td>\n",
       "      <td>[2.089026585978773, 1.0356926605543044, 0.7353...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9082</td>\n",
       "      <td>Lamb</td>\n",
       "      <td>Zero</td>\n",
       "      <td>-0.367547</td>\n",
       "      <td>-0.939283</td>\n",
       "      <td>LAMB: ZERO\\n\\nThere's no one here today\\n'Caus...</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/f65a72ecfbf7c304...</td>\n",
       "      <td>artist_and_song</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[0.054062437266111374, 0.38927221298217773, -0...</td>\n",
       "      <td>[0.8801736065962609, 1.9399530531306048, 2.596...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10587</td>\n",
       "      <td>Einstuerzende Neubauten</td>\n",
       "      <td>Youme &amp; Meyou</td>\n",
       "      <td>0.526139</td>\n",
       "      <td>-1.628377</td>\n",
       "      <td>They build a ship each wintertime\\nFor launch ...</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/a2acca0ac29d3a0a...</td>\n",
       "      <td>artist_and_song</td>\n",
       "      <td>Relaxed</td>\n",
       "      <td>[-1.2014904022216797, -0.5136592388153076, -0....</td>\n",
       "      <td>[0.5157966639886593, 1.5658099646756507, 1.259...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9177</td>\n",
       "      <td>Mouse On Mars</td>\n",
       "      <td>Wipe That Sound</td>\n",
       "      <td>0.815393</td>\n",
       "      <td>0.662457</td>\n",
       "      <td>Kick the can\\nI kick, kick kick the can\\nI kic...</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/a803171c426e144d...</td>\n",
       "      <td>artist_and_song</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[-0.42865195870399475, 0.8299823999404907, 1.1...</td>\n",
       "      <td>[2.3368670630266033, 1.3798174751404781, 0.647...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              artist_name       track_name   valence   arousal  \\\n",
       "0        6481            Alexz Johnson      White Lines  0.678952 -2.333604   \n",
       "1        9075          Turntablerocker        No Melody  0.373325 -0.923151   \n",
       "2        9082                     Lamb             Zero -0.367547 -0.939283   \n",
       "3       10587  Einstuerzende Neubauten    Youme & Meyou  0.526139 -1.628377   \n",
       "4        9177            Mouse On Mars  Wipe That Sound  0.815393  0.662457   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  I tried to tell you\\nI've got to get away\\nI t...   \n",
       "1  We've got the song\\nBut they got no melody\\nNo...   \n",
       "2  LAMB: ZERO\\n\\nThere's no one here today\\n'Caus...   \n",
       "3  They build a ship each wintertime\\nFor launch ...   \n",
       "4  Kick the can\\nI kick, kick kick the can\\nI kic...   \n",
       "\n",
       "                                           audio_url    search_method  \\\n",
       "0  https://p.scdn.co/mp3-preview/eae97329ac7135a5...  artist_and_song   \n",
       "1  https://p.scdn.co/mp3-preview/4f397176ee912edf...  artist_and_song   \n",
       "2  https://p.scdn.co/mp3-preview/f65a72ecfbf7c304...  artist_and_song   \n",
       "3  https://p.scdn.co/mp3-preview/a2acca0ac29d3a0a...  artist_and_song   \n",
       "4  https://p.scdn.co/mp3-preview/a803171c426e144d...  artist_and_song   \n",
       "\n",
       "   emotion                                   lyrics_embedding  \\\n",
       "0  Relaxed  [0.5272476077079773, 1.168580174446106, 0.1721...   \n",
       "1  Relaxed  [-0.5302870273590088, -1.6064175367355347, 1.8...   \n",
       "2      Sad  [0.054062437266111374, 0.38927221298217773, -0...   \n",
       "3  Relaxed  [-1.2014904022216797, -0.5136592388153076, -0....   \n",
       "4    Happy  [-0.42865195870399475, 0.8299823999404907, 1.1...   \n",
       "\n",
       "                                     audio_embedding  label  \n",
       "0  [0.7431232416583579, 0.20046921661336187, 0.23...      2  \n",
       "1  [2.089026585978773, 1.0356926605543044, 0.7353...      2  \n",
       "2  [0.8801736065962609, 1.9399530531306048, 2.596...      3  \n",
       "3  [0.5157966639886593, 1.5658099646756507, 1.259...      2  \n",
       "4  [2.3368670630266033, 1.3798174751404781, 0.647...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('database/LaA_train.csv')\n",
    "df_test = pd.read_csv('database/LaA_test.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_audio_train = df_train['audio_embedding'].apply(ast.literal_eval).apply(np.array)\n",
    "x_audio_train = np.stack(embeddings_audio_train.values)\n",
    "embeddings_audio_test = df_test['audio_embedding'].apply(ast.literal_eval).apply(np.array)\n",
    "x_audio_test = np.stack(embeddings_audio_test.values)\n",
    "\n",
    "embeddings_lyrics_train = df_train['lyrics_embedding'].apply(ast.literal_eval).apply(np.array)\n",
    "x_lyrics_train = np.stack(embeddings_lyrics_train.values)\n",
    "embeddings_lyrics_test = df_test['lyrics_embedding'].apply(ast.literal_eval).apply(np.array)\n",
    "x_lyrics_test = np.stack(embeddings_lyrics_test.values)\n",
    "\n",
    "y_train = df_train['label']\n",
    "y_test = df_test['label']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Either train SVMs again or load it \n",
    "if loaded watch out that same data split and same datascaler, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"# Initialize and train the SVM classifier on the scaled dataset\n",
    "svm_classifier_lyrics = SVC(kernel='rbf', C=1, gamma='auto', probability=True)\n",
    "svm_classifier_lyrics.fit(x_lyrics_train, y_train)\n",
    "print(\"Lyrics SVM trained\")\n",
    "svm_classifier_audio = SVC(kernel='rbf', C=1, gamma='auto', probability=True)\n",
    "svm_classifier_audio.fit(x_audio_train, y_train)\n",
    "print(\"Audio SVM trained\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_svm_audio = 'models/SVM_audio.joblib'\n",
    "name_svm_lyrics = 'models/SVM_lyrics.joblib'\n",
    "svm_classifier_audio = load(name_svm_audio)\n",
    "svm_classifier_lyrics = load(name_svm_lyrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the probabilities\n",
    "y_pred_test_prob_lyrics = svm_classifier_lyrics.predict_proba(x_lyrics_test)\n",
    "y_pred_test_prob_audio = svm_classifier_audio.predict_proba(x_audio_test)\n",
    "y_pred_train_prob_lyrics = svm_classifier_lyrics.predict_proba(x_lyrics_train)\n",
    "y_pred_train_prob_audio = svm_classifier_audio.predict_proba(x_audio_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics accuracy: 0.43\n",
      "Audio accuracy: 0.42\n"
     ]
    }
   ],
   "source": [
    "#get labels\n",
    "y_pred_lyrics = np.argmax(y_pred_test_prob_lyrics, axis=1)\n",
    "y_pred_audio = np.argmax(y_pred_test_prob_audio, axis=1)\n",
    "\n",
    "acc_lyrics, acc_audio = accuracy_score(y_test, y_pred_lyrics), accuracy_score(y_test, y_pred_audio)\n",
    "print(f\"Lyrics accuracy: {acc_lyrics:.2f}\")\n",
    "print(f\"Audio accuracy: {acc_audio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First kind of models take probabilities and are simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1 accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "#First model takes the highest probability of the two added models\n",
    "y_pred_max_combined = np.argmax(y_pred_test_prob_lyrics + y_pred_test_prob_audio, axis=1)\n",
    "acc_max_combined = accuracy_score(y_test, y_pred_max_combined)\n",
    "print(f\"Accuracy: {acc_max_combined:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V2 accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Second model takes the higher probability of the model\n",
    "y_pred_max = np.argmax(np.maximum(y_pred_test_prob_lyrics, y_pred_test_prob_audio), axis=1)\n",
    "acc_max = accuracy_score(y_test, y_pred_max)\n",
    "print(f\"Accuracy: {acc_max:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second kind of models take probabilities as new input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_meta_train = np.hstack((y_pred_train_prob_lyrics, y_pred_train_prob_audio))\n",
    "x_meta_test = np.hstack((y_pred_test_prob_lyrics, y_pred_test_prob_audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V3 accuracy: 0.43\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "meta_classifier_forest = RandomForestClassifier()\n",
    "meta_classifier_forest.fit(x_meta_train, y_train)\n",
    "y_pred_forest = meta_classifier_forest.predict(x_meta_test)\n",
    "acc_forest = accuracy_score(y_test, y_pred_forest)\n",
    "print(f\"Accuracy: {acc_forest:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Using the same meta features as before\n",
    "meta_classifier_lr = LogisticRegression(max_iter=1000)\n",
    "meta_classifier_lr.fit(x_meta_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = meta_classifier_lr.predict(x_meta_test)\n",
    "acc_meta_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Accuracy: {acc_meta_lr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.7354363799095154\n",
      "Epoch 2/20, Loss: 0.5320879817008972\n",
      "Epoch 3/20, Loss: 0.5591878890991211\n",
      "Epoch 4/20, Loss: 0.515727162361145\n",
      "Epoch 5/20, Loss: 0.6375213861465454\n",
      "Epoch 6/20, Loss: 0.7026153206825256\n",
      "Epoch 7/20, Loss: 0.46629008650779724\n",
      "Epoch 8/20, Loss: 0.7474197745323181\n",
      "Epoch 9/20, Loss: 0.6568333506584167\n",
      "Epoch 10/20, Loss: 0.4438040554523468\n",
      "Epoch 11/20, Loss: 0.8439077734947205\n",
      "Epoch 12/20, Loss: 0.5823493599891663\n",
      "Epoch 13/20, Loss: 0.389651358127594\n",
      "Epoch 14/20, Loss: 0.7707103490829468\n",
      "Epoch 15/20, Loss: 0.3900233507156372\n",
      "Epoch 16/20, Loss: 0.6029807925224304\n",
      "Epoch 17/20, Loss: 0.580782413482666\n",
      "Epoch 18/20, Loss: 0.7533096075057983\n",
      "Epoch 19/20, Loss: 0.6467638611793518\n",
      "Epoch 20/20, Loss: 0.743520975112915\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "x_meta_train_tensor = torch.tensor(x_meta_train, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "x_meta_test_tensor = torch.tensor(x_meta_test, dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(x_meta_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataset = TensorDataset(x_meta_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "class MetaClassifierNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MetaClassifierNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)  # First hidden layer\n",
    "        self.fc2 = nn.Linear(128, 64)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(64, num_classes)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = MetaClassifierNN(input_size=8, num_classes=4)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Clear gradients for this training step\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Apply gradients\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 43.64%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad(): \n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy_NN = correct / total\n",
    "print(f'Accuracy on the test set: {accuracy_NN * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
