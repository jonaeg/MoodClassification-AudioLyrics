{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure for the presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "- Explain what we're going to do: Music classification using lyrics and audio, and trying to combine the two \n",
    "- Mention deezer paper, looked for the titles, used API's to get the lyrical and audio data\n",
    "- Explain the valence-arousal scale, that we used the four different quadrants as emotions, how we called them\n",
    "- Describe size and distribution of our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Audio model\n",
    "\n",
    "- Explain the audio features we used: Mel frequency cepstral coefficients, Mel spectrogram, Chroma Vector, Tonal Centroid features\n",
    "- Explain how we extracted the features using Librosa, taking 1 min samples, explain that each feature set is estimated on time dt\n",
    "- Explain which features we used in the end: Max, Min, Mean, to get about 500 audio features per song \n",
    "- Explain that we tried to do Principal component analysis to shrink the feature space to perform SVM, but didn't get better results than full feature space\n",
    "- Mention rescaling of the datapoints when performing SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lyrics model\n",
    "\n",
    "- Explain how to get lyrics embedding, word vs sentence to vec etc\n",
    "- Geht es schÃ¶ner? Ja es gibt Jona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combined models\n",
    "\n",
    "- Explain the principal of ensemble / multimodal learning: Take two models and combine them \n",
    "- Explain how to get confidential values out of an SVM, since we need them for the combined models\n",
    "- **First model:** Just take the sum of the confidential values. Adjusted: Weighted voting, include the accuracies of the given models on the training set in their votes\n",
    "- **Second model:** Take the models decision which is more confident. Adjusted: Weight the confidence values of a model for a given class with its accuracy in the given class\n",
    "- **Third model:** Logistic regression, Neural Net -> Don't get better result (same for logreg, but less transparent)\n",
    "- Probably don't mention: RandomForrestClassifier, SVM on whole featurespace (maybe mention that we even tried out more combinations)\n",
    "- **Conclusion:** For the analysis we take the confident-based voting, since it's the easiest and best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysis\n",
    "\n",
    "- Mention accuracies for the different models (train and test!), and of the combined model. Then: Further analysis taking the confident-based voting into account\n",
    "- Show confusion matrix for the different models, mention that the models are way better in classifying happy and sad than angry and relaxed, maybe because of emotion being stronger\n",
    "- Show ROC curves for different models for different emotions, mention that we had to binarize the labels and probabilities\n",
    "- Look at table on which emotion the models disagree, talk about lower and upper bound for combining the two models, that we're closer to the upper bound\n",
    "- Mention that we also investigated on how certain the models are with their decision depending on if it's right or wrong and emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Discussion\n",
    "\n",
    "### 6.1 Audio features\n",
    "- To improve: We could take more \"fine tuned\" features in a temporal sense, instead of taking the max, min, mean, take more finetuned featuers\n",
    "- We took the first minute \n",
    "- Could take longer audio files, mention \n",
    "\n",
    "### 6.2 Lyrical features \n",
    "- Mention we could e.g. improve embedding, use lyrics embedding instead of plain text etc\n",
    "\n",
    "### 6.3 Combined model\n",
    "- Mention we could maybe try to train a more sophisticated neural network, or use a neural network taking into account not only the accuracy scores but all features -> Deep learning"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
